# -*- coding: utf-8 -*-
"""FaceNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BzW-OGflhZv238vOWBzeEE72zFdwAf8F
"""

#Links used directly in the Creation of my work
#https://www.atmosera.com/blog/facial-recognition-with-cnns/
#https://www.tensorflow.org/tutorials/images/classification
#https://colab.research.google.com/drive/1C8tLA5__49o-_3vFk3paxPMfHOgYUctG?usp=sharing
#https://towardsdatascience.com/face-detection-in-2-minutes-using-opencv-python-90f89d7c0f81
#https://github.com/opencv/opencv/tree/master/data/haarcascades
#https://docs.python.org/3/library/pickle.html
#https://keras.io/api


import numpy as np
import tensorflow as tf
import keras
from keras import layers
from keras.models import Model
from keras.models import Sequential
from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Rescaling, Resizing, Dropout, Normalization
from keras.applications import ResNet50
from matplotlib import pyplot as plt
import pandas as pd
from PIL import Image
import pathlib
import cv2
import pickle
from keras.models import load_model
from google.colab import drive
from google.colab.patches import cv2_imshow
from keras.applications.vgg16 import VGG16


drive.mount('/content/drive')
device_name = tf.test.gpu_device_name()

path = "drive/My Drive/KaggleChallenge"

y_train_path = "drive/My Drive/KaggleChallenge/y_train_strict"
with open(y_train_path, "rb") as output:
    y_train = pickle.load(output)

x_test_path = "drive/My Drive/KaggleChallenge/test_imgs_strict"
with open(x_test_path, "rb") as output:
    testing = pickle.load(output)

x_train_path = "drive/My Drive/KaggleChallenge/x_train_strict"
with open(x_train_path, "rb") as output:
    x_train = pickle.load(output)

x_train = np.asarray(x_train)
y_train = np.asarray(y_train)

print("x_train shape:", x_train.shape)
print("y_train shape:", y_train.shape)

categories = pd.read_csv("drive/My Drive/KaggleChallenge/category.csv")
name_list = categories.pop("Category")

y_train_digits = []
for name in y_train:
    i = 0
    for check in name_list:
        if (name == check):
            y_train_digits.append(i)
        i = i + 1

y_train = keras.utils.to_categorical(y_train_digits, num_classes=100)

print("x_train shape:", x_train.shape)
print("y_train shape:", y_train.shape)

i = 0
trainSize = 50000
x_train_new = []
y_train_new = []
x_test = []
y_test = []
while i < len(y_train):
  if i < trainSize:
    x_train_new.append(x_train[i])
    y_train_new.append(y_train[i])
  else:
    x_test.append(x_train[i])
    y_test.append(y_train[i])
  i = i + 1

x_train = np.asarray(x_train_new)
y_train = np.asarray(y_train_new)
x_test = np.asarray(x_test)
y_test = np.asarray(y_test)

print("x_train shape:", x_train.shape)
print("y_train shape:", y_train.shape)
print("x_test shape:", x_test.shape)
print("y_test shape:", y_test.shape)
print(x_train.shape[0], "train samples")
print(x_test.shape[0], "test samples")

shape = (128, 128, 3)
n_class = 100

data_augmentation = keras.Sequential(
  [
    layers.RandomFlip("horizontal", input_shape=(128,128,3)),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1),
  ]
)

# base_model = VGG16(weights='imagenet', include_top=False)
# base_model.trainable = False
# model = Sequential()
# model.add(data_augmentation)
# model.add(Resizing(224, 224))
# model.add(base_model)
# model.add(Flatten())
# model.add(Dropout(0.2))
# model.add(Dense(1024, activation='relu'))
# model.add(Dense(n_class, activation='softmax'))
# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
# model.build((None, 128, 128, 3))
# model.summary()

model = Sequential()
model.add(data_augmentation)
model.add(Normalization())
model.add(Rescaling(1./255, input_shape=(shape)))
model.add(Conv2D(32, (4, 4), activation='silu'))
model.add(MaxPooling2D(2, 2))
model.add(Conv2D(32, (4, 4), activation='silu'))
model.add(MaxPooling2D(2, 2))
model.add(Conv2D(64, (4, 4), activation='silu'))
model.add(MaxPooling2D(2, 2))
model.add(Conv2D(64, (4, 4), activation='silu'))
model.add(MaxPooling2D(2, 2))
model.add(Conv2D(64, (4, 4), activation='silu'))
model.add(MaxPooling2D(2, 2))
model.add(Dropout(0.2))
model.add(Flatten())
model.add(Dense(1024, activation='relu'))
model.add(Dense(n_class, activation='softmax'))
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

#model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=128, epochs=26)
model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=256, epochs=60)
model.save('FaceRecSwishBigKern.keras')
print('Model Saved')

numImages = 4977
numGood = 4312
i = 0
id = []
Category = []
while i < numImages:
  if (i % 100 == 0):
    print(f"Testing Image: {i}/{numImages}")
  try:
    img_path = f"drive/My Drive/KaggleChallenge/test_imgs_crop/{i}.jpg"
    #img = keras.utils.load_img(img_path, target_size=(128, 128))
    #img = cv2.imread(img_path)
    #img_array = np.expand_dims(img_array, 0) # Create a batch
    img = testing[i]
    guess = np.asarray(img)
    guess = np.expand_dims(img, 0)
    guess = model.predict(guess, verbose=0)
    guess = name_list[np.argmax(guess)]
    # print(f"Label {i}: {guess}")
    # cv2_imshow(img)
  except:
    guess= ['NONE']
  Category.append(guess)
  id.append(i)
  i = i + 1
Category = pd.DataFrame(Category)
id = pd.DataFrame(id)
#array = pd.concat((id, Category), axis = 1)
df = pd.DataFrame(Category)
df.to_csv('4layer4KernCNNSwish.csv')